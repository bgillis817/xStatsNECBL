# Load required libraries
suppressPackageStartupMessages({
  if (!require(pacman)) install.packages("pacman")
  pacman::p_load(
    dplyr, readr, data.table,
    ggplot2, gridExtra, viridis,
    tidyr, lubridate, stringr, googledrive
  )
})

# Set up Google Drive authentication
options(gargle_oauth_cache = ".secrets")
drive_auth(cache = ".secrets", email = TRUE)

# ===================================================================
# PHASE 1: CSV COMBINATION
# ===================================================================

combine_navs_csvs <- function(folder_path = "Navs CSVs", use_google_drive = TRUE) {
  
  cat("COMBINING CSV FILES\n")
  cat("===========================\n")
  
  if (use_google_drive) {
    cat("Looking in Google Drive folder:", folder_path, "\n")
    
    # Find the folder in Google Drive
    folder <- drive_find(folder_path, type = "folder")
    
    if (nrow(folder) == 0) {
      cat("Google Drive folder not found:", folder_path, "\n")
      return(NULL)
    }
    
    # Get all CSV files in the folder
    csv_files <- drive_ls(folder, pattern = "\\.csv$")
    
    if (nrow(csv_files) == 0) {
      cat("No CSV files found in the Google Drive folder.\n")
      return(NULL)
    }
    
    cat("Found", nrow(csv_files), "CSV files in Google Drive\n")
    
    # Initialize combined data
    combined_data <- data.frame()
    
    # Process each CSV file from Google Drive
    for (i in 1:nrow(csv_files)) {
      file_name <- csv_files$name[i]
      cat("Processing:", file_name, "\n")
      
      tryCatch({
        # Download to temporary location
        temp_file <- tempfile(fileext = ".csv")
        drive_download(csv_files$id[i], path = temp_file, overwrite = TRUE, verbose = FALSE)
        
        # Read the downloaded file
        current_data <- read_csv(temp_file, show_col_types = FALSE)
        
        # Clean up temp file
        unlink(temp_file)
        
        # Standardize column names
        required_cols <- c("ExitSpeed", "Angle", "PlayResult")
        alternative_names <- list(
          ExitSpeed = c("ExitSpeed", "Exit_Speed", "exit_speed", "EV", "ev"),
          Angle = c("Angle", "Launch_Angle", "launch_angle", "LA", "la"),
          PlayResult = c("PlayResult", "Play_Result", "play_result", "Result", "result", "Outcome", "outcome")
        )
        
        for (req_col in required_cols) {
          possible_names <- alternative_names[[req_col]]
          for (alt_name in possible_names) {
            if (alt_name %in% names(current_data) && !req_col %in% names(current_data)) {
              names(current_data)[names(current_data) == alt_name] <- req_col
              break
            }
          }
        }
        
        # Add source file info
        current_data$source_file <- file_name
        current_data$file_index <- i
        
        # Combine data
        if (nrow(combined_data) == 0) {
          combined_data <- current_data
        } else {
          combined_data <- bind_rows(combined_data, current_data)
        }
        
        cat("  Added", nrow(current_data), "rows\n")
        
      }, error = function(e) {
        cat("  Error processing", file_name, ":", e$message, "\n")
      })
    }
    
    cat("Combined", nrow(combined_data), "total rows from", nrow(csv_files), "files\n")
    
  } else {
    # Original local file logic
    cat("Looking in local folder:", folder_path, "\n")
    
    # Set working directory
    if (dir.exists(folder_path)) {
      setwd(folder_path)
      cat("Working directory set to:", getwd(), "\n")
    } else {
      cat("Folder not found:", folder_path, "\n")
      return(NULL)
    }
    
    # Find all CSV files
    csv_files <- list.files(pattern = "\\.csv$", full.names = FALSE)
    
    if (length(csv_files) == 0) {
      cat("No CSV files found in the folder.\n")
      return(NULL)
    }
    
    cat("Data Found", length(csv_files), "CSV files\n")
    
    # Initialize combined data
    combined_data <- data.frame()
    
    # Process each CSV file
    for (i in 1:length(csv_files)) {
      file <- csv_files[i]
      cat("Processing:", file, "\n")
      
      tryCatch({
        current_data <- read_csv(file, show_col_types = FALSE)
        
        # Standardize column names
        required_cols <- c("ExitSpeed", "Angle", "PlayResult")
        alternative_names <- list(
          ExitSpeed = c("ExitSpeed", "Exit_Speed", "exit_speed", "EV", "ev"),
          Angle = c("Angle", "Launch_Angle", "launch_angle", "LA", "la"),
          PlayResult = c("PlayResult", "Play_Result", "play_result", "Result", "result", "Outcome", "outcome")
        )
        
        for (req_col in required_cols) {
          possible_names <- alternative_names[[req_col]]
          for (alt_name in possible_names) {
            if (alt_name %in% names(current_data) && !req_col %in% names(current_data)) {
              names(current_data)[names(current_data) == alt_name] <- req_col
              break
            }
          }
        }
        
        # Add source file info
        current_data$source_file <- file
        current_data$file_index <- i
        
        # Combine data
        if (nrow(combined_data) == 0) {
          combined_data <- current_data
        } else {
          combined_data <- bind_rows(combined_data, current_data)
        }
        
        cat("  Added", nrow(current_data), "rows\n")
        
      }, error = function(e) {
        cat("  Error:", e$message, "\n")
      })
    }
    
    cat("Combined", nrow(combined_data), "total rows from", length(csv_files), "files\n")
  }
  
  return(combined_data)
}


clean_and_standardize_data <- function(combined_data) {
  
  cat("\n=== DATA CLEANING AND STANDARDIZATION ===\n")
  
  if (is.null(combined_data) || nrow(combined_data) == 0) {
    cat("No data provided for cleaning\n")
    return(NULL)
  }
  
  cat("Starting with", nrow(combined_data), "balls in play\n")
  
  # Check for required columns
  required_cols <- c("ExitSpeed", "Angle", "PlayResult")
  missing_cols <- required_cols[!required_cols %in% names(combined_data)]
  if (length(missing_cols) > 0) {
    cat("Missing required columns:", paste(missing_cols, collapse = ", "), "\n")
    return(NULL)
  }
  
  # Data cleaning pipeline
  clean_data <- combined_data %>%
    # Remove invalid exit velocities
    filter(!is.na(ExitSpeed), ExitSpeed >= 20, ExitSpeed <= 120) %>%
    # Remove invalid launch angles  
    filter(!is.na(Angle), Angle >= -90, Angle <= 90) %>%
    # Standardize outcome names
    mutate(
      outcome_clean = case_when(
        PlayResult %in% c("Single", "single", "1B") ~ "single",
        PlayResult %in% c("Double", "double", "2B") ~ "double", 
        PlayResult %in% c("Triple", "triple", "3B") ~ "triple",
        PlayResult %in% c("HomeRun", "home_run", "HR", "Home Run") ~ "home_run",
        PlayResult %in% c("Out", "out", "O") ~ "out",
        TRUE ~ "unknown"
      )
    ) %>%
    # Keep only valid outcomes
    filter(outcome_clean != "unknown") %>%
    # Add data quality flags
    mutate(
      ev_outlier = ExitSpeed > quantile(ExitSpeed, 0.99) | ExitSpeed < quantile(ExitSpeed, 0.01),
      la_outlier = abs(Angle) > quantile(abs(Angle), 0.99),
      data_quality = case_when(
        ev_outlier | la_outlier ~ "outlier",
        TRUE ~ "clean"
      )
    )
  
  # Data summary
  cat("Clean data summary:\n")
  cat("  - Total clean BIP:", nrow(clean_data), "\n")
  outcome_summary <- table(clean_data$outcome_clean)
  print(outcome_summary)
  
  return(clean_data)
}


engineer_xwoba_features <- function(clean_data) {
  
  cat("\n=== FEATURE ENGINEERING ===\n")
  
  # Extract key variables
  ev <- clean_data$ExitSpeed
  la <- clean_data$Angle
  n <- length(ev)
  
  # Physics calculations
  la_rad <- la * pi / 180
  
  cat("ðŸ”§ Creating feature categories:\n")
  
  # 1. Raw measurements
  cat("  - Raw measurements\n")
  raw_features <- data.frame(
    exit_velocity = ev,
    launch_angle = la
  )
  
  # 2. Polynomial features
  cat("  - Polynomial features\n")
  poly_features <- data.frame(
    ev_squared = ev^2,
    ev_cubed = ev^3,
    la_squared = la^2,
    la_cubed = la^3
  )
  
  # 3. Interaction features
  cat("  - Interaction features\n")
  interaction_features <- data.frame(
    ev_la = ev * la,
    ev_la_squared = ev * la^2,
    ev_squared_la = ev^2 * la,
    ev_squared_la_squared = ev^2 * la^2
  )
  
  # 4. Distance/Movementbased features
  cat("  - Physics-based features\n")
  physics_features <- data.frame(
    ev_la_ratio = ev / (abs(la) + 1),
    optimal_distance = sqrt((ev - 100)^2 + (la - 25)^2),
    sweet_spot_score = 1 / (1 + sqrt((ev - 100)^2 + (la - 25)^2)),
    optimal_angle_diff = abs(la - 25),
    angle_efficiency = cos(la_rad) * ev / 100,
    velocity_percentile = rank(ev) / n,
    angle_percentile = rank(la) / n
  )
  
  # 5. Trig featuree
  cat("  - Trigonometric features\n")
  trig_features <- data.frame(
    la_sin = sin(la_rad),
    la_cos = cos(la_rad),
    la_tan = tan(la_rad),
    ev_sin = ev * sin(la_rad),
    ev_cos = ev * cos(la_rad)
  )
  
  # 6. Categorical features
  cat("  - Categorical features\n")
  categorical_features <- data.frame(
    ev_elite = as.numeric(ev >= 100),
    ev_hard = as.numeric(ev >= 95 & ev < 100),
    ev_medium = as.numeric(ev >= 80 & ev < 95),
    ev_soft = as.numeric(ev < 80),
    la_popup = as.numeric(la > 50),
    la_flyball = as.numeric(la > 25 & la <= 50),
    la_line_drive = as.numeric(la >= 10 & la <= 25),
    la_ground_ball = as.numeric(la < 10),
    barrel = as.numeric(ev >= 98 & la >= 8 & la <= 32),
    solid_contact = as.numeric(ev >= 90 & la >= 8 & la <= 40),
    weak_contact = as.numeric(ev < 70 | abs(la) > 45)
  )
  
  # 7. Stat features
  cat("  - Statistical features\n")
  statistical_features <- data.frame(
    ev_z_score = scale(ev)[,1],
    la_z_score = scale(la)[,1],
    ev_rank = rank(ev),
    la_rank = rank(la)
  )
  
  # 8. Domain specific features
  cat("  - Domain-specific features\n")
  domain_features <- data.frame(
    hr_zone = as.numeric(ev >= 100 & la >= 20 & la <= 35),
    double_zone = as.numeric(ev >= 90 & la >= 10 & la <= 25),
    out_zone_popup = as.numeric(la > 45),
    out_zone_weak = as.numeric(ev < 70),
    high_value_zone = as.numeric(ev >= 90 & la >= 10 & la <= 40)
  )
  
  # 9. Sweet spot
  cat("  - Sweet spot analysis features\n")
  sweet_spot_features <- data.frame(
    sweet_spot_gradient = exp(-((ev - 100)^2 / 100 + (la - 25)^2 / 100)),
    barrel_plus = as.numeric(ev >= 100 & la >= 10 & la <= 30),
    elite_contact = as.numeric(ev >= 105 & la >= 15 & la <= 35),
    power_zone = as.numeric(ev >= 98 & la >= 22 & la <= 38),
    expected_distance_long = as.numeric(ev >= 95 & la >= 10 & la <= 40)
  )
  
  # Combine all features
  all_features <- cbind(
    raw_features,
    poly_features, 
    interaction_features,
    physics_features,
    trig_features,
    categorical_features,
    statistical_features,
    domain_features,
    sweet_spot_features
  )
  
  cat("Feature engineering complete; Created", ncol(all_features), "features\n")
  
  return(all_features)
}


# PHASE 4: SWEET SPOT ANALYSIS

analyze_sweet_spots <- function(clean_data, features) {
  
  cat("\n=== SWEET SPOT ANALYSIS ===\n")
  
  # Extract key variables
  ev <- clean_data$ExitSpeed
  la <- clean_data$Angle
  outcome <- clean_data$outcome_clean
  
  # Calculate actual wOBA for each ball
  woba_weights <- list(single = 0.888, double = 1.271, triple = 1.616, home_run = 2.101, out = 0.000)
  actual_woba <- ifelse(outcome == "single", woba_weights$single,
                ifelse(outcome == "double", woba_weights$double,
                ifelse(outcome == "triple", woba_weights$triple,
                ifelse(outcome == "home_run", woba_weights$home_run, woba_weights$out))))
  
  # Create EV/LA grid analysis
  cat("Creating EV/LA performance grid...\n")
  
  ev_bins <- seq(20, 120, by = 10)
  la_bins <- seq(-90, 90, by = 10)
  
  sweet_spot_grid <- data.frame()
  
  for (i in 1:(length(ev_bins)-1)) {
    for (j in 1:(length(la_bins)-1)) {
      ev_range <- c(ev_bins[i], ev_bins[i+1])
      la_range <- c(la_bins[j], la_bins[j+1])
      
      mask <- ev >= ev_range[1] & ev < ev_range[2] & la >= la_range[1] & la < la_range[2]
      
      if (sum(mask) >= 5) {
        sweet_spot_grid <- rbind(sweet_spot_grid, data.frame(
          ev_min = ev_range[1], ev_max = ev_range[2],
          la_min = la_range[1], la_max = la_range[2],
          sample_count = sum(mask),
          mean_woba = mean(actual_woba[mask]),
          hr_rate = mean(outcome[mask] == "home_run"),
          hit_rate = mean(outcome[mask] != "out")
        ))
      }
    }
  }
  
  # Sweet spot scoring
  sweet_spot_scores <- data.frame(
    exit_velocity = ev,
    launch_angle = la,
    actual_outcome = outcome,
    actual_woba = actual_woba,
    combined_score = (pmin(1, pmax(0, (ev - 60) / 40)) * 0.6 +
                     ifelse(la >= 10 & la <= 35, 1,
                            ifelse(la < 10, la / 10, 
                                   ifelse(la > 35, (90 - la) / 55, 0))) * 0.4)
  )
  
  cat("âœ… Sweet spot analysis complete!\n")
  
  return(list(
    grid_analysis = sweet_spot_grid,
    sweet_spot_scores = sweet_spot_scores
  ))
}


prepare_ml_training_datasets <- function(clean_data, features, sweet_spot_analysis) {
  
  cat("\n=== PREPARING DATASETS ===\n")
  
  # 2024 MLB wOBA weights (can add other stuff as time goes)
  woba_weights <- list(
    single = 0.888,
    double = 1.271,
    triple = 1.616, 
    home_run = 2.101,
    out = 0.000
  )
  
  # Create binary target variables
  targets <- data.frame(
    is_single = as.numeric(clean_data$outcome_clean == "single"),
    is_double = as.numeric(clean_data$outcome_clean == "double"),
    is_triple = as.numeric(clean_data$outcome_clean == "triple"), 
    is_homerun = as.numeric(clean_data$outcome_clean == "home_run"),
    is_out = as.numeric(clean_data$outcome_clean == "out")
  )
  
  # Calculate actual wOBA
  actual_woba <- ifelse(clean_data$outcome_clean == "single", woba_weights$single,
                ifelse(clean_data$outcome_clean == "double", woba_weights$double,
                ifelse(clean_data$outcome_clean == "triple", woba_weights$triple,
                ifelse(clean_data$outcome_clean == "home_run", woba_weights$home_run,
                woba_weights$out))))
  
  # Create training package
  training_package <- list(
    features = features,
    targets = targets,
    outcomes = clean_data$outcome_clean,
    actual_woba = actual_woba,
    sweet_spot_data = sweet_spot_analysis,
    raw_measurements = data.frame(
      exit_velocity = clean_data$ExitSpeed,
      launch_angle = clean_data$Angle,
      outcome_clean = clean_data$outcome_clean
    ),
    metadata = list(
      total_samples = nrow(clean_data),
      feature_count = ncol(features),
      woba_weights = woba_weights,
      outcome_distribution = table(clean_data$outcome_clean),
      data_date_created = Sys.time()
    )
  )
  
  cat("Training package complete:\n")
  cat("  - Samples:", nrow(clean_data), "\n")
  cat("  - Features:", ncol(features), "\n")
  cat("  - Mean wOBA:", round(mean(actual_woba), 3), "\n")
  
  return(training_package)
}

# ===================================================================
# MAIN PIPELINE FUNCTION
# ===================================================================

run_complete_xwoba_pipeline <- function(folder_path = "Navs CSVs", use_google_drive = TRUE) {
  
  cat("STARTING COMPLETE xwOBA PIPELINE\n")
  cat("====================================\n")
  
  # Phase 1: Combine CSV files
  cat("\nPHASE 1: COMBINING CSV FILES\n")
  combined_data <- combine_navs_csvs(folder_path, use_google_drive)
  if (is.null(combined_data)) return(NULL)
  
  # Save combined data
  saveRDS(combined_data, "navs_all_data.rds")
  cat("Saved combined data as navs_all_data.rds\n")
  
  # Phase 2: Clean and standardize
  cat("\nPHASE 2: DATA CLEANING\n")
  clean_data <- clean_and_standardize_data(combined_data)
  if (is.null(clean_data)) return(NULL)
  
  # Phase 3: Feature engineering
  cat("\n PHASE 3: FEATURE ENGINEERING\n")
  features <- engineer_xwoba_features(clean_data)
  
  # Phase 4: Sweet spot analysis
  cat("\n PHASE 4: SWEET SPOT ANALYSIS\n")
  sweet_spot_analysis <- analyze_sweet_spots(clean_data, features)
  
  # Phase 5: Prepare training datasets
  cat("\n PHASE 5: TRAINING DATA PREPARATION\n")
  training_package <- prepare_ml_training_datasets(clean_data, features, sweet_spot_analysis)
  
  # Save final package
  final_package <- list(
    training_data = training_package,
    clean_data = clean_data,
    engineered_features = features,
    sweet_spot_analysis = sweet_spot_analysis
  )
  
  saveRDS(final_package, "xwoba_data_engineering_package.rds")
  write.csv(cbind(training_package$features, training_package$targets), 
            "xwoba_training_data.csv", row.names = FALSE)
  
  cat("\n PIPELINE COMPLETE\n")
  cat("=====================\n")
  cat("Combined", nrow(clean_data), "balls in play\n")
  cat("Created", ncol(features), "features\n")
  cat("Sweet spot analysis complete\n")
  cat("Files created:\n")
  cat("   - xwoba_data_engineering_package.rds\n")
  cat("   - xwoba_training_data.csv\n")
  cat("   - navs_all_data.rds\n")
  
  return(final_package)
}
library(googledrive)
library(readr)
library(dplyr)
library(caret)
library(xgboost)

# Set up Google Drive authentication
options(gargle_oauth_cache = ".secrets")
drive_auth(cache = ".secrets", email = TRUE)


combine_navs_csvs <- function(folder_path = "Navs CSVs", use_google_drive = TRUE) {
  
  cat("COMBINING CSV FILES\n")
  cat("===========================\n")
  
  if (use_google_drive) {
    cat("Looking in Google Drive folder:", folder_path, "\n")
    
    # Find the folder in Google Drive
    folder <- drive_find(folder_path, type = "folder")
    
    if (nrow(folder) == 0) {
      cat("Google Drive folder not found:", folder_path, "\n")
      return(NULL)
    }
    
    # Get all CSV files in the folder
    csv_files <- drive_ls(folder, pattern = "\\.csv$")
    
    if (nrow(csv_files) == 0) {
      cat("No CSV files found in the Google Drive folder.\n")
      return(NULL)
    }
    
    cat("Found", nrow(csv_files), "CSV files in Google Drive\n")
    
    # Initialize combined data
    combined_data <- data.frame()
    
    # Process each CSV file from Google Drive
    for (i in 1:nrow(csv_files)) {
      file_name <- csv_files$name[i]
      cat("Processing:", file_name, "\n")
      
      tryCatch({
        # Download to temporary location
        temp_file <- tempfile(fileext = ".csv")
        drive_download(csv_files$id[i], path = temp_file, overwrite = TRUE, verbose = FALSE)
        
        # Read the downloaded file
        current_data <- read_csv(temp_file, show_col_types = FALSE)
        
        # Clean up temp file
        unlink(temp_file)
        
        # Standardize column names
        required_cols <- c("ExitSpeed", "Angle", "PlayResult")
        alternative_names <- list(
          ExitSpeed = c("ExitSpeed", "Exit_Speed", "exit_speed", "EV", "ev"),
          Angle = c("Angle", "Launch_Angle", "launch_angle", "LA", "la"),
          PlayResult = c("PlayResult", "Play_Result", "play_result", "Result", "result", "Outcome", "outcome")
        )
        
        for (req_col in required_cols) {
          possible_names <- alternative_names[[req_col]]
          for (alt_name in possible_names) {
            if (alt_name %in% names(current_data) && !req_col %in% names(current_data)) {
              names(current_data)[names(current_data) == alt_name] <- req_col
              break
            }
          }
        }
        
        # Add source file info
        current_data$source_file <- file_name
        current_data$file_index <- i
        
        # Combine data
        if (nrow(combined_data) == 0) {
          combined_data <- current_data
        } else {
          combined_data <- bind_rows(combined_data, current_data)
        }
        
        cat("  Added", nrow(current_data), "rows\n")
        
      }, error = function(e) {
        cat("  Error processing", file_name, ":", e$message, "\n")
      })
    }
    
    cat("Combined", nrow(combined_data), "total rows from", nrow(csv_files), "files\n")
    
  } else {
    # Original local file logic
    cat("Looking in local folder:", folder_path, "\n")
    
    # Set working directory
    if (dir.exists(folder_path)) {
      setwd(folder_path)
      cat("Working directory set to:", getwd(), "\n")
    } else {
      cat("Folder not found:", folder_path, "\n")
      return(NULL)
    }
    
    # Find all CSV files
    csv_files <- list.files(pattern = "\\.csv$", full.names = FALSE)
    
    if (length(csv_files) == 0) {
      cat("No CSV files found in the folder.\n")
      return(NULL)
    }
    
    cat("Data Found", length(csv_files), "CSV files\n")
    
    # Initialize combined data
    combined_data <- data.frame()
    
    # Process each CSV file
    for (i in 1:length(csv_files)) {
      file <- csv_files[i]
      cat("Processing:", file, "\n")
      
      tryCatch({
        current_data <- read_csv(file, show_col_types = FALSE)
        
        # Standardize column names
        required_cols <- c("ExitSpeed", "Angle", "PlayResult")
        alternative_names <- list(
          ExitSpeed = c("ExitSpeed", "Exit_Speed", "exit_speed", "EV", "ev"),
          Angle = c("Angle", "Launch_Angle", "launch_angle", "LA", "la"),
          PlayResult = c("PlayResult", "Play_Result", "play_result", "Result", "result", "Outcome", "outcome")
        )
        
        for (req_col in required_cols) {
          possible_names <- alternative_names[[req_col]]
          for (alt_name in possible_names) {
            if (alt_name %in% names(current_data) && !req_col %in% names(current_data)) {
              names(current_data)[names(current_data) == alt_name] <- req_col
              break
            }
          }
        }
        
        # Add source file info
        current_data$source_file <- file
        current_data$file_index <- i
        
        # Combine data
        if (nrow(combined_data) == 0) {
          combined_data <- current_data
        } else {
          combined_data <- bind_rows(combined_data, current_data)
        }
        
        cat("  Added", nrow(current_data), "rows\n")
        
      }, error = function(e) {
        cat("  Error:", e$message, "\n")
      })
    }
    
    cat("Combined", nrow(combined_data), "total rows from", length(csv_files), "files\n")
  }
  
  return(combined_data)
}

# ===================================================================
# PHASE 2: COMPLETE PIPELINE
# ===================================================================

run_complete_pipeline <- function() {
  
  cat("=== NAVS CSV PIPELINE START ===\n\n")
  
  # STEP 1: Combine CSVs from Google Drive
  cat("STEP 1: Combining CSV files from Google Drive...\n")
  combined_data <- combine_navs_csvs(folder_path = "Navs CSVs", use_google_drive = TRUE)
  
  if (is.null(combined_data) || nrow(combined_data) == 0) {
    cat("ERROR: No data was combined. Check Google Drive folder and files.\n")
    return(NULL)
  }
  
  # STEP 2: Save combined data
  cat("\nSTEP 2: Saving combined data...\n")
  saveRDS(combined_data, "navs_all_data.rds")
  cat("Saved", nrow(combined_data), "rows to navs_all_data.rds\n")
  
  # STEP 3: Data quality check
  cat("\nSTEP 3: Data quality check...\n")
  cat("Dataset dimensions:", nrow(combined_data), "rows x", ncol(combined_data), "columns\n")
  cat("Column names:", paste(names(combined_data), collapse = ", "), "\n")
  
  # Check required columns
  required_cols <- c("ExitSpeed", "Angle", "PlayResult")
  missing_cols <- setdiff(required_cols, names(combined_data))
  if(length(missing_cols) > 0) {
    cat("WARNING: Missing required columns:", paste(missing_cols, collapse = ", "), "\n")
  } else {
    cat("SUCCESS: All required columns present\n")
  }
  
  # Data completeness
  for(col in required_cols) {
    if(col %in% names(combined_data)) {
      complete_pct <- sum(!is.na(combined_data[[col]])) / nrow(combined_data) * 100
      cat(col, ":", round(complete_pct, 1), "% complete\n")
    }
  }
  
  # STEP 4: Set raw_data for the model
  raw_data <<- combined_data  # Make it available globally
  
  cat("\n=== DATA COMBINATION COMPLETE ===\n")
  cat("Ready to run xwOBA model with", nrow(raw_data), "rows of data\n")
  
  return(combined_data)
}

# ===================================================================
# EXECUTE PIPELINE
# ===================================================================

# Run the complete pipeline
cat("Starting Navs CSV Pipeline...\n")
pipeline_results <- run_complete_pipeline()

# Check if successful
if (!is.null(pipeline_results)) {
  cat("\n Pipeline completed successfully!\n")
  cat(" Data available as 'raw_data' with", nrow(raw_data), "rows\n")
  
  # Now you can run any of your models:
  cat("\nExample next steps:\n")
  cat("# Run your ultimate model:\n")
  cat("ultimate_results <- train_ultimate_performance_xwoba(raw_data)\n")
  cat("\n# Or run the advanced polynomial model:\n")
  cat("advanced_results <- train_advanced_polynomial_xwoba(raw_data)\n")
  cat("\n# Search for a player:\n")
  cat("player_results <- search_player_advanced(ultimate_results, raw_data, 'PlayerName')\n")
  
} else {
  cat("\nPipeline failed - check Google Drive authentication and folder access\n")
}
# Load required libraries
library(caret)
library(xgboost)
library(dplyr)

# Load data
raw_data <- readRDS('navs_all_data.rds')

# Feature Engineering Function
create_ultimate_features <- function(raw_data) {
  
  cat("\nUltimate Feature Engineering\n")
  cat("Creating 500+ features with emphasis on top performers\n\n")
  
  # Filter to batted balls with complete data
  pa_data <- raw_data %>%
    filter(
      PlayResult %in% c("Single", "Double", "Triple", "HomeRun", "Out", 
                        "FieldersChoice", "Error", "Sacrifice") &
      !is.na(ExitSpeed) & ExitSpeed > 0 &
      !is.na(Angle)
    )
  
  cat("Total batted balls:", nrow(pa_data), "\n")
  
  # Outcome classification
  pa_data$outcome <- case_when(
    pa_data$PlayResult %in% c("Single") ~ "single",
    pa_data$PlayResult %in% c("Double") ~ "double",
    pa_data$PlayResult %in% c("Triple") ~ "triple", 
    pa_data$PlayResult %in% c("HomeRun") ~ "home_run",
    pa_data$PlayResult %in% c("Out", "FieldersChoice", "Error", "Sacrifice") ~ "out",
    TRUE ~ "other"
  )
  
  pa_data <- pa_data[pa_data$outcome != "other", ]
  
  # Core measurements (keeping bearing for compatibility)
  ev <- pa_data$ExitSpeed
  la <- pa_data$Angle
  bearing <- ifelse(is.na(pa_data$Bearing), 0, pa_data$Bearing)
  
  # 1. Polynomial Features - PRIORITIZING TOP PERFORMERS
  extreme_polynomials <- data.frame(
    ev = ev,
    ev_2 = ev^2,
    ev_3 = ev^3,
    ev_4 = pmin(ev^4, 1e10),
    ev_5 = pmin(ev^5, 1e12),
    ev_6 = pmin(ev^6, 1e14),
    
    la = la,
    la_2 = la^2,
    la_3 = la^3,
    la_4 = pmin(la^4, 1e8),
    la_5 = pmin(la^5, 1e10),
    la_6 = pmin(la^6, 1e12),
    
    bearing = bearing,
    bearing_2 = bearing^2,
    bearing_3 = bearing^3,
    bearing_4 = bearing^4,
    bearing_abs = abs(bearing),
    bearing_abs_2 = abs(bearing)^2,
    bearing_abs_3 = abs(bearing)^3,
    
    ev_2_la_2 = ev^2 * la^2,
    ev_3_la_3 = pmin(ev^3 * la^3, 1e12),
    ev_4_la_4 = pmin(ev^4 * la^4, 1e15)
  )
  
  # 2. EV-LA Interactions - EMPHASIZING TOP FEATURES
  ev_la_features <- data.frame(
    # TOP PERFORMER #1: ev_2_la - multiple variations
    ev_2_la = ev^2 * la,
    
    ev_la = ev * la,
    ev_la_2 = ev * la^2,
    ev_la_3 = ev * la^3,
    ev_la_4 = ev * la^4,
    ev_la_5 = ev * la^5,
    
    ev_2_la_2 = ev^2 * la^2,
    ev_2_la_3 = ev^2 * la^3,
    ev_2_la_4 = ev^2 * la^4,
    
    # TOP PERFORMER #6: ev_3_la
    ev_3_la = ev^3 * la,
    ev_3_la_2 = ev^3 * la^2,
    ev_3_la_3 = pmin(ev^3 * la^3, 1e12),
    
    # TOP PERFORMER #5: ev_4_la_2
    ev_4_la = pmin(ev^4 * la, 1e10),
    ev_4_la_2 = pmin(ev^4 * la^2, 1e12),
    
    # TOP PERFORMER #7: ev_5_la and #4: ev_6_la
    ev_5_la = pmin(ev^5 * la, 1e12),
    ev_6_la = pmin(ev^6 * la, 1e14),
    
    ev_div_la = ifelse(abs(la) > 0.1, ev / abs(la), 0),
    la_div_ev = ifelse(ev > 0, la / ev, 0),
    
    ev_exp_la = ev * exp(pmin(abs(la) / 30, 3)),
    la_exp_ev = la * exp(pmin(ev / 100, 3))
  )
  
  # 3. Bearing and Field Position Features
  bearing_features <- data.frame(
    bearing_ev = abs(bearing) * ev,
    bearing_2_ev = bearing^2 * ev,
    bearing_ev_2 = abs(bearing) * ev^2,
    
    # TOP PERFORMER #8: bearing_3_ev
    bearing_3_ev = abs(bearing)^3 * ev,
    bearing_ev_3 = abs(bearing) * ev^3,
    
    bearing_la = abs(bearing) * abs(la),
    bearing_2_la = bearing^2 * abs(la),
    bearing_la_2 = abs(bearing) * la^2,
    
    bearing_ev_la = abs(bearing) * ev * abs(la) / 1000,
    bearing_2_ev_la = bearing^2 * ev * abs(la) / 10000,
    bearing_ev_2_la = abs(bearing) * ev^2 * abs(la) / 100000,
    
    # Field direction indicators
    field_direction_x = sin(bearing * pi / 180),
    field_direction_y = cos(bearing * pi / 180),
    field_direction_x_2 = (sin(bearing * pi / 180))^2,
    field_direction_y_2 = (cos(bearing * pi / 180))^2,
    field_direction_x_3 = (sin(bearing * pi / 180))^3,
    field_direction_y_3 = (cos(bearing * pi / 180))^3,
    
    center_field_bonus = (30 - pmin(abs(bearing), 30)) / 30,
    gap_penalty = pmax(0, (abs(bearing) - 20)) / 25,
    extreme_pull_penalty = pmax(0, (abs(bearing) - 40)) / 20
  )
  
  # 4. Outcome-Specific Zones
  outcome_zones <- data.frame(
    hr_zone_1 = as.numeric(ev >= 95 & la >= 20 & la <= 40),
    hr_zone_2 = as.numeric(ev >= 100 & la >= 15 & la <= 45),
    hr_zone_3 = as.numeric(ev >= 105 & la >= 10),
    hr_zone_4 = as.numeric(ev >= 98 & la >= 25 & la <= 35),
    hr_zone_5 = as.numeric(ev >= 92 & la >= 28 & la <= 32),
    hr_zone_6 = as.numeric(ev >= 110 & la >= 8),
    hr_zone_7 = as.numeric(ev >= 90 & la >= 30 & la <= 38),
    
    double_zone_1 = as.numeric(abs(bearing) > 20 & ev >= 80),
    double_zone_2 = as.numeric(la >= 5 & la <= 22 & ev >= 85),
    double_zone_3 = as.numeric(ev >= 90 & la >= 8 & la <= 25),
    double_zone_4 = as.numeric(abs(bearing) > 15 & ev >= 85),
    double_zone_5 = as.numeric(la >= 10 & la <= 30 & ev >= 88),
    
    single_zone_1 = as.numeric(la >= 0 & la <= 25 & ev >= 70 & ev < 95),
    single_zone_2 = as.numeric(ev >= 75 & la >= -5 & la <= 30),
    single_zone_3 = as.numeric(la >= -5 & la <= 30 & ev >= 65),
    single_zone_4 = as.numeric(ev >= 80 & la >= 0 & la <= 35),
    
    barrel_1 = as.numeric(ev >= 98 & la >= 26 & la <= 30),
    barrel_2 = as.numeric(ev >= 95 & la >= 24 & la <= 32),
    quality_1 = as.numeric(ev >= 85 & la >= 8 & la <= 32),
    quality_2 = as.numeric(ev >= 80 & la >= 10 & la <= 30),
    elite_1 = as.numeric(ev >= 100 & la >= 15 & la <= 35),
    elite_2 = as.numeric(ev >= 95 & la >= 20 & la <= 40)
  )
  
  # 5. Interaction Combinations - EMPHASIZING TOP FEATURES
  mega_combos <- data.frame(
    ev_la_bearing = ev * la * abs(bearing) / 1000,
    
    power_score_1 = ev^2 * pmax(0, la) / 1000,
    power_score_2 = ev^2 * pmax(0, (la - 10)) / 1000,
    power_score_3 = ev^2 * pmax(0, (la - 15)) / 1000,
    power_score_4 = ev^3 * pmax(0, la) / 100000,
    
    contact_score_1 = ev * (1 / (1 + abs(la - 20))) * (1 / (1 + abs(bearing) / 30)) / 100,
    contact_score_2 = ev * (1 / (1 + abs(la - 25))) * (1 / (1 + abs(bearing) / 40)) / 100,
    contact_score_3 = ev * (1 / (1 + abs(la - 22))) / 10,
    
    ev_percentile = rank(ev) / length(ev),
    bearing_percentile = (rank(bearing) + length(bearing)) / (2 * length(bearing)),
    
    optimal_combination_1 = ev * (40 - abs(la - 20)) * (45 - pmin(abs(bearing), 45)) / 10000,
    # TOP PERFORMER #3: optimal_combination_2
    optimal_combination_2 = ev^2 * (35 - abs(la - 25)) / 1000,
    optimal_combination_3 = ev * la * (1 / (1 + abs(bearing) / 30)) / 100,
    
    # TOP PERFORMER #2: ev_la_optimal
    ev_la_optimal = ev * pmax(0, 30 - abs(la - 20)) / 100,
    ev_bearing_optimal = ev * pmax(0, 40 - abs(bearing)) / 100,
    la_bearing_combo = abs(la) * abs(bearing) / 100,
    
    # Trajectory quality indicators
    trajectory_quality_1 = ev * (1 / (1 + abs(la - 20))) / 10,
    trajectory_quality_2 = ev * (1 / (1 + abs(la - 25))) / 10,
    trajectory_quality_3 = ev * (1 / (1 + abs(la - 30))) / 10,
    
    # Advanced angle interactions
    optimal_la_factor = pmax(0, 35 - abs(la - 22)) / 35,
    launch_efficiency = ev * pmax(0, 30 - abs(la - 20)) / 1000,
    bearing_efficiency = ev * pmax(0, 35 - abs(bearing)) / 1000,
    
    # Additional variations of top performers
    ev_2_la_alt = ev^2 * pmax(0, la) / 1000,
    ev_la_optimal_alt = ev * pmax(0, 25 - abs(la - 22)) / 100,
    optimal_combination_2_alt = ev^2 * (30 - abs(la - 20)) / 1000,
    bearing_3_ev_alt = abs(bearing)^3 * ev / 1000,
    ev_4_la_2_alt = pmin(ev^4 * la^2, 1e12) / 1000000,
    ev_3_la_alt = ev^3 * pmax(0, la) / 100000,
    ev_5_la_alt = pmin(ev^5 * pmax(0, la), 1e12) / 1000000000,
    ev_6_la_alt = pmin(ev^6 * pmax(0, la), 1e14) / 1000000000000
  )
  
  # Combine all features
  all_features <- cbind(
    extreme_polynomials,
    ev_la_features,
    bearing_features,
    outcome_zones,
    mega_combos
  )
  
  # Clean extreme values
  all_features[is.infinite(as.matrix(all_features))] <- 0
  all_features[abs(as.matrix(all_features)) > 1e15] <- 0
  all_features[is.na(all_features)] <- 0
  
  cat("\nFeature engineering complete\n")
  cat("Total features created:", ncol(all_features), "\n")
  cat("Total batted balls processed:", nrow(all_features), "\n")
  
  return(list(
    features = all_features,
    outcomes = pa_data$outcome,
    pa_data = pa_data
  ))
}

# Model Training Function
train_maximum_correlation_xwoba <- function(raw_data) {
  
  cat("\nMaximum Correlation xwOBA Model Training\n")
  cat("Goal: Push correlation above 80% with emphasis on top features\n\n")
  
  # Create features
  feature_result <- create_ultimate_features(raw_data)
  features <- feature_result$features
  outcomes <- feature_result$outcomes
  
  # Prepare targets
  outcome_mapping <- c("out" = 0, "single" = 1, "double" = 2, "triple" = 3, "home_run" = 4)
  y_class <- outcome_mapping[outcomes]
  
  # Calculate actual wOBA
  woba_weights <- c("out" = 0.000, "single" = 0.888, "double" = 1.271, 
                    "triple" = 1.616, "home_run" = 2.101)
  actual_woba <- woba_weights[outcomes]
  
  cat("Model summary:\n")
  cat("Features:", ncol(features), "\n")
  cat("Samples:", nrow(features), "\n")
  cat("Mean wOBA:", round(mean(actual_woba), 3), "\n")
  
  # Train/test split
  set.seed(42)
  train_idx <- createDataPartition(outcomes, p = 0.7, list = FALSE)
  remaining_idx <- setdiff(1:length(outcomes), train_idx)
  
  val_idx <- createDataPartition(outcomes[remaining_idx], p = 0.5, list = FALSE)
  test_idx <- setdiff(1:length(remaining_idx), val_idx)
  
  final_val_idx <- remaining_idx[val_idx]
  final_test_idx <- remaining_idx[test_idx]
  
  # Split data
  X_train <- as.matrix(features[train_idx, ])
  X_val <- as.matrix(features[final_val_idx, ])
  X_test <- as.matrix(features[final_test_idx, ])
  
  y_train <- y_class[train_idx]
  y_val <- y_class[final_val_idx]
  y_test <- y_class[final_test_idx]
  
  woba_train <- actual_woba[train_idx]
  woba_val <- actual_woba[final_val_idx]
  woba_test <- actual_woba[final_test_idx]
  
  # Create DMatrix
  dtrain <- xgb.DMatrix(data = X_train, label = y_train)
  dval <- xgb.DMatrix(data = X_val, label = y_val)
  dtest <- xgb.DMatrix(data = X_test, label = y_test)
  
  # Model parameters
  params <- list(
    objective = "multi:softprob",
    eval_metric = "mlogloss",
    num_class = 5,
    
    max_depth = 10,
    eta = 0.02,
    subsample = 0.9,
    colsample_bytree = 0.7,
    min_child_weight = 3,
    reg_alpha = 0.01,
    reg_lambda = 0.1,
    gamma = 0.01,
    
    seed = 42
  )
  
  cat("Training model...\n")
  
  # Train model
  model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = 3000,
    watchlist = list(train = dtrain, val = dval),
    early_stopping_rounds = 150,
    verbose = 1,
    print_every_n = 300
  )
  
  # Get predictions
  test_probs <- predict(model, dtest, reshape = TRUE)
  colnames(test_probs) <- c("P_out", "P_single", "P_double", "P_triple", "P_home_run")
  
  # Calculate xwOBA
  woba_weights_vector <- c(0.000, 0.888, 1.271, 1.616, 2.101)
  predicted_xwoba <- as.vector(test_probs %*% woba_weights_vector)
  
  # Evaluation
  correlation <- cor(predicted_xwoba, woba_test)
  mae <- mean(abs(predicted_xwoba - woba_test))
  rmse <- sqrt(mean((predicted_xwoba - woba_test)^2))
  
  pred_class <- apply(test_probs, 1, which.max) - 1
  class_accuracy <- mean(pred_class == y_test)
  
  t_test_result <- t.test(predicted_xwoba, woba_test, paired = TRUE)
  
  brier_scores <- numeric(5)
  for(i in 1:5) {
    actual_binary <- as.numeric(y_test == (i-1))
    predicted_prob <- test_probs[, i]
    brier_scores[i] <- mean((predicted_prob - actual_binary)^2)
  }
  overall_brier <- mean(brier_scores)
  
  cat("\nModel Results:\n")
  cat("Correlation:", round(correlation, 4), "\n")
  cat("MAE:", round(mae, 4), "\n")
  cat("RMSE:", round(rmse, 4), "\n")
  cat("Classification Accuracy:", round(class_accuracy, 4), "\n")
  cat("t-test p-value:", round(t_test_result$p.value, 6), "\n")
  cat("Brier Score:", round(overall_brier, 4), "\n")
  
  if(t_test_result$p.value > 0.05) {
    cat("Well-calibrated probabilities maintained\n")
  } else {
    cat("Some calibration trade-off for correlation\n")
  }
  
  importance <- xgb.importance(model = model)
  cat("\nTop 25 Most Important Features:\n")
  print(head(importance, 25))
  
  return(list(
    model = model,
    correlation = correlation,
    mae = mae,
    rmse = rmse,
    class_accuracy = class_accuracy,
    t_test_p = t_test_result$p.value,
    brier_score = overall_brier,
    predictions = predicted_xwoba,
    probabilities = test_probs,
    actual = woba_test,
    importance = importance,
    feature_count = ncol(X_train)
  ))
}

# Full xwOBA Calculation Function
calculate_full_xwoba <- function(raw_data, model_results) {
  
  all_pa <- raw_data %>% filter(!is.na(Batter))
  
  all_pa$outcome <- case_when(
    all_pa$PlayResult %in% c("Single", "Double", "Triple", "HomeRun") ~ "hit",
    all_pa$PlayResult %in% c("Out", "FieldersChoice", "Error") ~ "out",
    all_pa$PlayResult %in% c("Sacrifice") ~ "sacrifice_fly",
    all_pa$KorBB == "Walk" ~ "walk",
    all_pa$KorBB == "IntentionalWalk" ~ "intentional_walk",
    all_pa$PitchCall == "HitByPitch" ~ "hit_by_pitch",
    all_pa$KorBB %in% c("Strikeout", "StrikeoutLooking", "StrikeoutSwinging") ~ "strikeout",
    TRUE ~ "other"
  )
  
  classified_pa <- all_pa[all_pa$outcome != "other", ]
  
  hits <- sum(classified_pa$outcome == "hit")
  outs <- sum(classified_pa$outcome == "out")
  strikeouts <- sum(classified_pa$outcome == "strikeout")
  BB <- sum(classified_pa$outcome == "walk")
  IBB <- sum(classified_pa$outcome == "intentional_walk")
  SF <- sum(classified_pa$outcome == "sacrifice_fly")
  HBP <- sum(classified_pa$outcome == "hit_by_pitch")
  
  batted_balls <- hits + outs
  AB <- hits + outs + strikeouts
  denominator <- AB + BB - IBB + SF + HBP
  
  mean_xwoba_con <- mean(model_results$predictions, na.rm = TRUE)
  
  wBB_HBP <- 0.690
  
  numerator <- (mean_xwoba_con * batted_balls) + (wBB_HBP * (BB - IBB + HBP))
  full_xwoba <- numerator / denominator
  
  cat("Full xwOBA calculation:\n")
  cat("Batted balls:", batted_balls, "\n")
  cat("Walks (BB):", BB, "\n")
  cat("HBP:", HBP, "\n")
  cat("Mean xwOBA (contact):", round(mean_xwoba_con, 3), "\n")
  cat("Full xwOBA:", round(full_xwoba, 3), "\n")
  
  return(full_xwoba)
}

# Run the complete model
ultimate_results <- train_maximum_correlation_xwoba(raw_data)
full_xwoba_result <- calculate_full_xwoba(raw_data, ultimate_results)

# Get key results
mean_xwobacon <- mean(ultimate_results$predictions, na.rm = TRUE)
correlation <- ultimate_results$correlation

cat("\nFinal Results:\n")
cat("Mean xwOBAcon:", round(mean_xwobacon, 3), "\n")
cat("Full xwOBA:", round(full_xwoba_result, 3), "\n") 
cat("Correlation:", round(correlation, 4), "\n")
